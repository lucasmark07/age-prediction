{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzB+vTqDC74eqyqlPzDuV7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucasmark07/age-prediction/blob/main/Age_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LTsaKxuAV489",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8af4401-f6fb-4872-a181-20fc9e01e756"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NHANES Age Classification Project\n",
            "Predicting Senior (65+) vs Adult (<65) categories\n",
            "==================================================\n",
            "============================================================\n",
            "1. DATA LOADING AND INITIAL EXPLORATION\n",
            "============================================================\n",
            "✓ Training data loaded successfully\n",
            "Shape of the training dataset: (1966, 10)\n",
            "\n",
            "First 5 rows of the training dataset:\n",
            "      SEQN  RIDAGEYR  RIAGENDR  PAQ605  BMXBMI  LBXGLU  DIQ010  LBXGLT  LBXIN  \\\n",
            "0  73564.0      61.0       2.0     2.0    35.7   110.0     2.0   150.0  14.91   \n",
            "1  73568.0      26.0       2.0     2.0    20.3    89.0     2.0    80.0   3.85   \n",
            "2  73576.0      16.0       1.0     2.0    23.2    89.0     2.0    68.0   6.14   \n",
            "3  73577.0      32.0       1.0     2.0    28.9   104.0     NaN    84.0  16.15   \n",
            "4  73580.0      38.0       2.0     1.0    35.9   103.0     2.0    81.0  10.92   \n",
            "\n",
            "  age_group  \n",
            "0     Adult  \n",
            "1     Adult  \n",
            "2     Adult  \n",
            "3     Adult  \n",
            "4     Adult  \n",
            "\n",
            "Information about the training dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1966 entries, 0 to 1965\n",
            "Data columns (total 10 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   SEQN       1954 non-null   float64\n",
            " 1   RIDAGEYR   1957 non-null   float64\n",
            " 2   RIAGENDR   1948 non-null   float64\n",
            " 3   PAQ605     1953 non-null   float64\n",
            " 4   BMXBMI     1948 non-null   float64\n",
            " 5   LBXGLU     1953 non-null   float64\n",
            " 6   DIQ010     1948 non-null   float64\n",
            " 7   LBXGLT     1955 non-null   float64\n",
            " 8   LBXIN      1957 non-null   float64\n",
            " 9   age_group  1952 non-null   object \n",
            "dtypes: float64(9), object(1)\n",
            "memory usage: 153.7+ KB\n",
            "None\n",
            "\n",
            "Descriptive statistics of the training dataset:\n",
            "               SEQN     RIDAGEYR     RIAGENDR       PAQ605       BMXBMI  \\\n",
            "count   1954.000000  1957.000000  1948.000000  1953.000000  1948.000000   \n",
            "mean   78683.621801    42.005621     1.510267     1.825397    27.965400   \n",
            "std     2924.115709    20.147601     0.500023     0.399449     7.327616   \n",
            "min    73564.000000    12.000000     1.000000     1.000000    14.500000   \n",
            "25%    76194.000000    24.000000     1.000000     2.000000    22.800000   \n",
            "50%    78717.000000    41.000000     2.000000     2.000000    26.800000   \n",
            "75%    81217.000000    58.000000     2.000000     2.000000    31.300000   \n",
            "max    83727.000000    80.000000     2.000000     7.000000    70.100000   \n",
            "\n",
            "            LBXGLU       DIQ010       LBXGLT        LBXIN  \n",
            "count  1953.000000  1948.000000  1955.000000  1957.000000  \n",
            "mean     99.491039     2.015914   115.150384    11.862892  \n",
            "std      16.774665     0.187579    46.271615     9.756713  \n",
            "min      63.000000     1.000000    40.000000     0.140000  \n",
            "25%      91.000000     2.000000    87.000000     5.800000  \n",
            "50%      97.000000     2.000000   105.000000     9.030000  \n",
            "75%     104.000000     2.000000   131.000000    14.480000  \n",
            "max     405.000000     3.000000   604.000000   102.290000  \n",
            "\n",
            "Missing values in each column of the training dataset:\n",
            "SEQN         12\n",
            "RIDAGEYR      9\n",
            "RIAGENDR     18\n",
            "PAQ605       13\n",
            "BMXBMI       18\n",
            "LBXGLU       13\n",
            "DIQ010       18\n",
            "LBXGLT       11\n",
            "LBXIN         9\n",
            "age_group    14\n",
            "dtype: int64\n",
            "\n",
            "============================================================\n",
            "2. DATA PREPROCESSING AND FEATURE ENGINEERING\n",
            "============================================================\n",
            "✓ Data preprocessing completed\n",
            "Shape of processed training dataset: (1966, 11)\n",
            "\n",
            "First 5 rows of processed training dataset:\n",
            "   RIDAGEYR  BMXBMI  LBXGLU  LBXGLT  LBXIN  is_senior  RIAGENDR_2  PAQ605_2  \\\n",
            "0      61.0    35.7   110.0   150.0  14.91          0        True      True   \n",
            "1      26.0    20.3    89.0    80.0   3.85          0        True      True   \n",
            "2      16.0    23.2    89.0    68.0   6.14          0       False      True   \n",
            "3      32.0    28.9   104.0    84.0  16.15          0       False      True   \n",
            "4      38.0    35.9   103.0    81.0  10.92          0        True     False   \n",
            "\n",
            "   PAQ605_7  DIQ010_2  DIQ010_3  \n",
            "0     False      True     False  \n",
            "1     False      True     False  \n",
            "2     False      True     False  \n",
            "3     False      True     False  \n",
            "4     False      True     False  \n",
            "\n",
            "============================================================\n",
            "3. MODEL TRAINING AND EVALUATION\n",
            "============================================================\n",
            "Starting hyperparameter tuning...\n",
            "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
            "\n",
            "Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.7}\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "ROC AUC Score: 1.0000\n",
            "Model saved as xgboost_model.pkl\n",
            "\n",
            "============================================================\n",
            "4. RESULTS ANALYSIS AND VISUALIZATION\n",
            "============================================================\n",
            "Saved confusion_matrix_xgb.png\n",
            "Saved roc_curve_xgb.png\n",
            "\n",
            "============================================================\n",
            "5. GENERATE SUBMISSION FILE\n",
            "============================================================\n",
            "✓ Test data loaded successfully\n",
            "✓ Submission file generated as submission.csv\n",
            "\n",
            "==================================================\n",
            "RESULTS\n",
            "==================================================\n",
            "- Model training completed\n",
            "- Used XGBoost with grid search for hyperparameters\n",
            "- Handled missing data with mean/mode imputation\n",
            "- Generated confusion matrix and ROC curve plots\n",
            "- Created submission.csv file\n",
            "\n",
            "Done! Check the output files.\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "NHANES Age Prediction: Senior vs. Adult\n",
        "This script builds a machine learning model to predict whether an individual\n",
        "from the NHANES dataset is a 'Senior' (65+) or 'Adult' (under 65).\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                           f1_score, roc_auc_score, confusion_matrix,\n",
        "                           ConfusionMatrixDisplay, RocCurveDisplay)\n",
        "import joblib\n",
        "import sys\n",
        "import os\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"Load the training data and perform initial exploration.\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"1. DATA LOADING AND INITIAL EXPLORATION\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        train_df = pd.read_csv(\"Train_Data.csv\")\n",
        "        print(\"✓ Training data loaded successfully\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: Train_Data.csv not found. Please ensure it's in the same directory.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    print(f'Shape of the training dataset: {train_df.shape}')\n",
        "    print('\\nFirst 5 rows of the training dataset:')\n",
        "    print(train_df.head())\n",
        "    print('\\nInformation about the training dataset:')\n",
        "    print(train_df.info())\n",
        "    print('\\nDescriptive statistics of the training dataset:')\n",
        "    print(train_df.describe())\n",
        "    print('\\nMissing values in each column of the training dataset:')\n",
        "    print(train_df.isnull().sum())\n",
        "\n",
        "    return train_df\n",
        "\n",
        "def preprocess_data(df, is_train=True):\n",
        "    \"\"\"Preprocess the data with imputation and encoding.\"\"\"\n",
        "    original_seq_numbers = None\n",
        "    if not is_train and \"SEQN\" in df.columns:\n",
        "        original_seq_numbers = df[\"SEQN\"]\n",
        "\n",
        "    categorical_features = [\"RIAGENDR\", \"PAQ605\", \"DIQ010\"]\n",
        "\n",
        "    numerical_cols = df.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n",
        "    if \"SEQN\" in numerical_cols:\n",
        "        numerical_cols.remove(\"SEQN\")\n",
        "\n",
        "    # Impute numerical features\n",
        "    imputer_numerical = SimpleImputer(strategy='mean')\n",
        "    df[numerical_cols] = imputer_numerical.fit_transform(df[numerical_cols])\n",
        "\n",
        "    # Impute categorical features\n",
        "    for col in categorical_features:\n",
        "        if col in df.columns:\n",
        "            imputer_categorical = SimpleImputer(strategy='most_frequent')\n",
        "            df[col] = imputer_categorical.fit_transform(df[[col]])\n",
        "            df[col] = df[col].astype(int).astype(str)\n",
        "\n",
        "    # Create target variable for training data\n",
        "    if is_train:\n",
        "        df[\"is_senior\"] = (df[\"RIDAGEYR\"] >= 65).astype(int)\n",
        "        if 'age_group' in df.columns:\n",
        "            df.drop(columns=['age_group'], inplace=True)\n",
        "\n",
        "    # One-hot encoding\n",
        "    df = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
        "\n",
        "    # Remove SEQN column\n",
        "    if \"SEQN\" in df.columns:\n",
        "        df.drop(columns=[\"SEQN\"], inplace=True)\n",
        "\n",
        "    if not is_train:\n",
        "        return df, original_seq_numbers\n",
        "    return df\n",
        "\n",
        "def train_model(processed_train_df):\n",
        "    \"\"\"Train XGBoost model with hyperparameter tuning.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"3. MODEL TRAINING AND EVALUATION\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    X = processed_train_df.drop(columns=[\"is_senior\"])\n",
        "    y = processed_train_df[\"is_senior\"]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # Initialize XGBoost model\n",
        "    model = XGBClassifier(random_state=42, eval_metric='logloss')\n",
        "\n",
        "    # Define parameter grid\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [3, 5, 7],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'subsample': [0.7, 0.8, 0.9]\n",
        "    }\n",
        "\n",
        "    print(\"Starting hyperparameter tuning...\")\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=model, param_grid=param_grid, cv=5,\n",
        "        scoring='accuracy', n_jobs=-1, verbose=1\n",
        "    )\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    y_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "    print(f\"\\nBest Hyperparameters: {grid_search.best_params_}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "    print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "    # Save model\n",
        "    joblib.dump(best_model, 'xgboost_model.pkl')\n",
        "    print(\"Model saved as xgboost_model.pkl\")\n",
        "\n",
        "    return best_model, X_test, y_test, y_pred\n",
        "\n",
        "def visualize_results(best_model, X_test, y_test, y_pred):\n",
        "    \"\"\"Create visualizations for model performance.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"4. RESULTS ANALYSIS AND VISUALIZATION\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    disp_cm = ConfusionMatrixDisplay(\n",
        "        confusion_matrix=cm, display_labels=[\"Not Senior\", \"Senior\"]\n",
        "    )\n",
        "    disp_cm.plot()\n",
        "    plt.title(\"Confusion Matrix - XGBoost\")\n",
        "    plt.savefig(\"confusion_matrix_xgb.png\")\n",
        "    plt.close()\n",
        "    print(\"Saved confusion_matrix_xgb.png\")\n",
        "\n",
        "    # ROC Curve\n",
        "    disp_roc = RocCurveDisplay.from_estimator(best_model, X_test, y_test)\n",
        "    plt.title(\"ROC Curve - XGBoost\")\n",
        "    plt.savefig(\"roc_curve_xgb.png\")\n",
        "    plt.close()\n",
        "    print(\"Saved roc_curve_xgb.png\")\n",
        "\n",
        "def generate_submission(best_model, processed_train_df):\n",
        "    \"\"\"Generate submission file with predictions.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"5. GENERATE SUBMISSION FILE\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        test_df = pd.read_csv(\"Test_Data.csv\")\n",
        "        print(\"✓ Test data loaded successfully\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: Test_Data.csv not found. Please ensure it's in the same directory.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    processed_test_df, original_test_seq_numbers = preprocess_data(\n",
        "        test_df.copy(), is_train=False\n",
        "    )\n",
        "\n",
        "    # Ensure test set columns match training set columns\n",
        "    train_cols = processed_train_df.drop(columns=[\"is_senior\"]).columns\n",
        "    processed_test_df = processed_test_df.reindex(columns=train_cols, fill_value=0)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = best_model.predict(processed_test_df)\n",
        "\n",
        "    # Create submission file\n",
        "    submission_df = pd.DataFrame({\n",
        "        \"SEQN\": original_test_seq_numbers,\n",
        "        \"age_group\": predictions\n",
        "    })\n",
        "    submission_df.to_csv(\"submission.csv\", index=False)\n",
        "    print(\"✓ Submission file generated as submission.csv\")\n",
        "\n",
        "    return submission_df\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function.\"\"\"\n",
        "    print(\"NHANES Age Classification Project\")\n",
        "    print(\"Predicting Senior (65+) vs Adult (<65) categories\")\n",
        "    print(\"=\"*50)\n",
        "    # Load and explore data\n",
        "    train_df = load_data()\n",
        "\n",
        "    # Preprocess data\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"2. DATA PREPROCESSING AND FEATURE ENGINEERING\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    processed_train_df = preprocess_data(train_df.copy(), is_train=True)\n",
        "    processed_train_df.to_csv(\"processed_train_data.csv\", index=False)\n",
        "    print(\"✓ Data preprocessing completed\")\n",
        "    print(f\"Shape of processed training dataset: {processed_train_df.shape}\")\n",
        "    print(\"\\nFirst 5 rows of processed training dataset:\")\n",
        "    print(processed_train_df.head())\n",
        "\n",
        "    # Train model\n",
        "    best_model, X_test, y_test, y_pred = train_model(processed_train_df)\n",
        "\n",
        "    # Visualize results\n",
        "    visualize_results(best_model, X_test, y_test, y_pred)\n",
        "\n",
        "    # Generate submission\n",
        "    submission_df = generate_submission(best_model, processed_train_df)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"RESULTS\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"- Model training completed\")\n",
        "    print(\"- Used XGBoost with grid search for hyperparameters\")\n",
        "    print(\"- Handled missing data with mean/mode imputation\")\n",
        "    print(\"- Generated confusion matrix and ROC curve plots\")\n",
        "    print(\"- Created submission.csv file\")\n",
        "    print(\"\\nDone! Check the output files.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}